{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f3907cb",
   "metadata": {},
   "source": [
    "# 03 - YOLO video demo for work zone detection\n",
    "\n",
    "This notebook loads the trained YOLO model (`best.pt`), runs it on a video,\n",
    "computes a simple `work_zone_score` per frame, overlays boxes and a banner,\n",
    "and writes an annotated video file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773930e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: c:\\Users\\wesle\\Music\\workingzone\\runs_workzone\\yolov8s_workzone\\weights\\best.pt\n",
      "Input video: c:\\Users\\wesle\\Music\\workingzone\\data\\demo\\boston_workzone_short.mp4\n",
      "Output video: c:\\Users\\wesle\\Music\\workingzone\\runs_workzone\\video_demos\\boston_workzone_annotated.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesle\\anaconda3\\envs\\slt311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Paths\n",
    "project_dir = Path.cwd()  # adjust if needed\n",
    "run_dir = project_dir / \"runs_workzone\" / \"yolov8s_workzone\"  # or your actual run\n",
    "best_ckpt = run_dir / \"weights\" / \"best.pt\"\n",
    "\n",
    "# Input and output videos\n",
    "input_video = project_dir / \"data\" / \"demo\" / \"boston_workzone_short.mp4\"  # change path\n",
    "output_dir = project_dir / \"runs_workzone\" / \"video_demos\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_video = output_dir / \"boston_workzone_annotated.mp4\"\n",
    "\n",
    "# Detection settings\n",
    "conf_thres = 0.4\n",
    "iou_thres = 0.5\n",
    "\n",
    "print(\"Best checkpoint:\", best_ckpt)\n",
    "print(\"Input video:\", input_video)\n",
    "print(\"Output video:\", output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e1061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {0: 'Cone', 1: 'Drum', 2: 'Barricade', 3: 'Barrier', 4: 'Vertical Panel', 5: 'Work Vehicle', 6: 'Worker', 7: 'Arrow Board', 8: 'Temporary Traffic Control Message Board', 9: 'Temporary Traffic Control Sign'}\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(str(best_ckpt))\n",
    "names = model.model.names  # class index -> name\n",
    "print(\"Classes:\", names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c559ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which classes indicate work zone and their weights\n",
    "workzone_weights = {\n",
    "    \"Cone\": 1.0,\n",
    "    \"Drum\": 1.2,\n",
    "    \"Barricade\": 1.5,\n",
    "    \"Barrier\": 1.0,\n",
    "    \"Vertical Panel\": 1.0,\n",
    "    \"Work Vehicle\": 2.0,\n",
    "    \"Worker\": 2.5,\n",
    "    \"Arrow Board\": 1.5,\n",
    "    \"Temporary Traffic Control Message Board\": 1.5,\n",
    "    \"Temporary Traffic Control Sign\": 1.2,\n",
    "}\n",
    "\n",
    "def compute_work_zone_score(result):\n",
    "    \"\"\"\n",
    "    result is a single ultralytics Result object for one frame.\n",
    "    Returns a scalar score in [0, 1] (roughly).\n",
    "    \"\"\"\n",
    "    if result.boxes is None or len(result.boxes) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    cls_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
    "    confs = result.boxes.conf.cpu().numpy()\n",
    "    \n",
    "    score = 0.0\n",
    "    max_possible = 0.0\n",
    "    \n",
    "    for cls_id, conf in zip(cls_ids, confs):\n",
    "        cls_name = names.get(cls_id, str(cls_id))\n",
    "        weight = workzone_weights.get(cls_name, 0.0)\n",
    "        score += weight * float(conf)\n",
    "        max_possible += weight\n",
    "    \n",
    "    if max_possible == 0.0:\n",
    "        return 0.0\n",
    "    # Normalize to [0, 1] by dividing by max_possible and clipping\n",
    "    return float(np.clip(score / max_possible, 0.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2414276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: 722x406 at 30.0 fps, 451 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:   0%|          | 0/451 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video: 100%|██████████| 451/451 [00:14<00:00, 32.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated video to: c:\\Users\\wesle\\Music\\workingzone\\runs_workzone\\video_demos\\boston_workzone_annotated.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(str(input_video))\n",
    "assert cap.isOpened(), f\"Cannot open video {input_video}\"\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "writer = cv2.VideoWriter(str(output_video), fourcc, fps, (width, height))\n",
    "\n",
    "print(f\"Video info: {width}x{height} at {fps:.1f} fps, {total_frames} frames\")\n",
    "\n",
    "frame_scores = []\n",
    "\n",
    "for _ in tqdm(range(total_frames), desc=\"Processing video\"):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run YOLO on current frame\n",
    "    results = model(frame, conf=conf_thres, iou=iou_thres, verbose=False)\n",
    "    result = results[0]\n",
    "    \n",
    "    # Compute scene score\n",
    "    score = compute_work_zone_score(result)\n",
    "    frame_scores.append(score)\n",
    "    \n",
    "    # Get image with bounding boxes drawn by Ultralytics\n",
    "    annotated = result.plot()  # returns BGR numpy array\n",
    "    \n",
    "    # Compose banner text\n",
    "    if score > 0.6:\n",
    "        label_text = f\"WORK ZONE - score {score:.2f}\"\n",
    "        banner_color = (0, 0, 255)  # red\n",
    "    elif score > 0.3:\n",
    "        label_text = f\"POSSIBLE WORK ZONE - score {score:.2f}\"\n",
    "        banner_color = (0, 165, 255)  # orange\n",
    "    else:\n",
    "        label_text = f\"NO WORK ZONE - score {score:.2f}\"\n",
    "        banner_color = (0, 255, 0)  # green\n",
    "    \n",
    "    # Draw banner rectangle at top\n",
    "    banner_height = int(0.08 * height)\n",
    "    cv2.rectangle(\n",
    "        annotated,\n",
    "        (0, 0),\n",
    "        (width, banner_height),\n",
    "        banner_color,\n",
    "        thickness=-1,\n",
    "    )\n",
    "    \n",
    "    # Put text\n",
    "    cv2.putText(\n",
    "        annotated,\n",
    "        label_text,\n",
    "        (20, int(banner_height * 0.7)),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.9,\n",
    "        (255, 255, 255),\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "    \n",
    "    # Write to output\n",
    "    writer.write(annotated)\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "print(\"Saved annotated video to:\", output_video)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slt311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
